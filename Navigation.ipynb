{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State size: 37\n",
      "Action space: 4\n"
     ]
    }
   ],
   "source": [
    "from dqn_agent import Agent\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# Load the environment\n",
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\", no_graphics=True)\n",
    "\n",
    "# get the environment default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# size of the state perceived by the brain\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "state = env_info.vector_observations[0]\n",
    "state_size = len(state)\n",
    "print(\"State size: {}\".format(state_size))\n",
    "\n",
    "# size of the possible actions the brain can perform\n",
    "action_size = brain.vector_action_space_size\n",
    "print(\"Action space: {}\".format(action_size))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the agent that will control the default brain\n",
    "agent = Agent(state_size=state_size, action_size=action_size, seed=0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the agent\n",
    "\n",
    "def dqn(n_episodes=10000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int):      maximum number of training episodes\n",
    "        max_t (int):           maximum number of timesteps\n",
    "        eps_start (float):     initial value of epsilon, use to selected the greedy action\n",
    "        eps_end (float):       minimum value of epsilon\n",
    "        eps_decay (float):     factor to decay epsilon by multiplication\n",
    "    \n",
    "    \"\"\"\n",
    "    # Define the monitoring metrics\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=100)\n",
    "    eps = eps_start\n",
    "    for i_episodes in range(1, n_episodes +1):\n",
    "        # reset the environment\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        # get the current state and reset episod score to 0\n",
    "        state = env_info.vector_observations[0]\n",
    "        score = 0\n",
    "        # execute the time steps up to max_t\n",
    "        for step in range(max_t):\n",
    "            # determine what action to take based on the state, epsilon\n",
    "            # using the local network in evaluation mode to not avoid\n",
    "            # doing an operation that will modify the weights.\n",
    "            # It returns the greedy-action based on the epsilon calculation\n",
    "            action = agent.act(state, eps)\n",
    "            # execute the selected action, which produces an object with\n",
    "            # the environment state variables\n",
    "            env_info = env.step(action)[brain_name]\n",
    "            next_state = env_info.vector_observations[0]\n",
    "            reward = env_info.rewards[0]\n",
    "            done = env_info.local_done[0]\n",
    "            # Based on the observation make the agent learn\n",
    "            agent.step(state, action, reward, next_state,done)\n",
    "            # update the state to reflex you are in the next_state\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            # check if reached a terminal state\n",
    "            if done:\n",
    "                break\n",
    "        # store the episode score in the queue to collect a\n",
    "        # history of the last 100 episodes score\n",
    "        scores_window.append(score)\n",
    "        # save the score in a list \n",
    "        scores.append(score)\n",
    "        # time to decay epsilon selecting the greater of two\n",
    "        # value our smaller limit or the decayed eps\n",
    "        eps = max(eps_end, eps_decay*eps)\n",
    "        # print the average of the last 100 episodes.\n",
    "        #print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episodes,\n",
    "        #                                                   np.mean(scores_window)),\n",
    "        #     end=\"\")\n",
    "        # every 100 episodes print the ALL TIME score using all the episodes\n",
    "        # scores from episode one until now\n",
    "        if i_episodes % 100 == 0:\n",
    "            print('Episode {}\\tAverage Score so far: {:.2f}'.format(i_episodes,\n",
    "                                                              np.mean(scores)))\n",
    "        # check if the RL problem got solve by checking if the average \n",
    "        # of the last 100 episodes is greater than 22 \n",
    "        if np.mean(scores_window) >= 22.0:\n",
    "            import torch\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episodes-100,\n",
    "                                                                                        np.mean(scores_window)))\n",
    "            # saved the DL weights and architecture that solve the problem\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "        \n",
    "    # return all the scores of all the episodes\n",
    "    return scores\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score so far: 0.28\n",
      "Episode 200\tAverage Score so far: 0.74\n",
      "Episode 300\tAverage Score so far: 0.97\n",
      "Episode 400\tAverage Score so far: 1.30\n",
      "Episode 500\tAverage Score so far: 1.77\n",
      "Episode 600\tAverage Score so far: 2.48\n",
      "Episode 700\tAverage Score so far: 3.35\n",
      "Episode 800\tAverage Score so far: 3.84\n",
      "Episode 900\tAverage Score so far: 4.32\n",
      "Episode 1000\tAverage Score so far: 5.04\n",
      "Episode 1100\tAverage Score so far: 5.48\n",
      "Episode 1200\tAverage Score so far: 5.79\n",
      "Episode 1300\tAverage Score so far: 6.00\n",
      "Episode 1400\tAverage Score so far: 6.36\n",
      "Episode 1500\tAverage Score so far: 6.74\n",
      "Episode 1600\tAverage Score so far: 6.95\n",
      "Episode 1700\tAverage Score so far: 7.04\n",
      "Episode 1800\tAverage Score so far: 7.20\n",
      "Episode 1900\tAverage Score so far: 7.35\n",
      "Episode 2000\tAverage Score so far: 7.59\n",
      "Episode 2100\tAverage Score so far: 7.85\n",
      "Episode 2200\tAverage Score so far: 8.01\n",
      "Episode 2300\tAverage Score so far: 7.98\n",
      "Episode 2400\tAverage Score so far: 8.04\n",
      "Episode 2500\tAverage Score so far: 8.16\n",
      "Episode 2600\tAverage Score so far: 8.28\n",
      "Episode 2700\tAverage Score so far: 8.36\n",
      "Episode 2800\tAverage Score so far: 8.50\n",
      "Episode 2900\tAverage Score so far: 8.61\n",
      "Episode 3000\tAverage Score so far: 8.74\n",
      "Episode 3100\tAverage Score so far: 8.85\n",
      "Episode 3200\tAverage Score so far: 8.97\n",
      "Episode 3300\tAverage Score so far: 8.99\n",
      "Episode 3400\tAverage Score so far: 9.09\n",
      "Episode 3500\tAverage Score so far: 9.19\n",
      "Episode 3600\tAverage Score so far: 9.29\n",
      "Episode 3700\tAverage Score so far: 9.37\n",
      "Episode 3800\tAverage Score so far: 9.39\n",
      "Episode 3900\tAverage Score so far: 9.42\n",
      "Episode 4000\tAverage Score so far: 9.52\n",
      "Episode 4100\tAverage Score so far: 9.63\n",
      "Episode 4200\tAverage Score so far: 9.70\n",
      "Episode 4300\tAverage Score so far: 9.78\n",
      "Episode 4400\tAverage Score so far: 9.84\n",
      "Episode 4500\tAverage Score so far: 9.90\n",
      "Episode 4600\tAverage Score so far: 9.95\n",
      "Episode 4700\tAverage Score so far: 10.02\n",
      "Episode 4800\tAverage Score so far: 10.05\n",
      "Episode 4900\tAverage Score so far: 10.09\n",
      "Episode 5000\tAverage Score so far: 10.14\n",
      "Episode 5100\tAverage Score so far: 10.17\n",
      "Episode 5200\tAverage Score so far: 10.18\n",
      "Episode 5300\tAverage Score so far: 10.22\n",
      "Episode 5400\tAverage Score so far: 10.23\n",
      "Episode 5500\tAverage Score so far: 10.26\n",
      "Episode 5600\tAverage Score so far: 10.30\n",
      "Episode 5700\tAverage Score so far: 10.32\n",
      "Episode 5800\tAverage Score so far: 10.38\n",
      "Episode 5900\tAverage Score so far: 10.44\n",
      "Episode 6000\tAverage Score so far: 10.49\n",
      "Episode 6100\tAverage Score so far: 10.52\n",
      "Episode 6200\tAverage Score so far: 10.54\n",
      "Episode 6300\tAverage Score so far: 10.56\n",
      "Episode 6400\tAverage Score so far: 10.60\n",
      "Episode 6500\tAverage Score so far: 10.63\n",
      "Episode 6600\tAverage Score so far: 10.69\n",
      "Episode 6700\tAverage Score so far: 10.75\n",
      "Episode 6800\tAverage Score so far: 10.77\n",
      "Episode 6900\tAverage Score so far: 10.78\n",
      "Episode 7000\tAverage Score so far: 10.81\n",
      "Episode 7100\tAverage Score so far: 10.85\n",
      "Episode 7200\tAverage Score so far: 10.88\n",
      "Episode 7300\tAverage Score so far: 10.91\n",
      "Episode 7400\tAverage Score so far: 10.93\n",
      "Episode 7500\tAverage Score so far: 10.93\n",
      "Episode 7600\tAverage Score so far: 10.96\n",
      "Episode 7700\tAverage Score so far: 10.99\n",
      "Episode 7800\tAverage Score so far: 11.02\n",
      "Episode 7900\tAverage Score so far: 11.05\n",
      "Episode 8000\tAverage Score so far: 11.07\n",
      "Episode 8100\tAverage Score so far: 11.08\n",
      "Episode 8200\tAverage Score so far: 11.09\n",
      "Episode 8300\tAverage Score so far: 11.12\n",
      "Episode 8400\tAverage Score so far: 11.13\n",
      "Episode 8500\tAverage Score so far: 11.14\n",
      "Episode 8600\tAverage Score so far: 11.15\n",
      "Episode 8700\tAverage Score so far: 11.16\n",
      "Episode 8800\tAverage Score so far: 11.18\n",
      "Episode 8900\tAverage Score so far: 11.22\n",
      "Episode 9000\tAverage Score so far: 11.21\n",
      "Episode 9100\tAverage Score so far: 11.23\n",
      "Episode 9200\tAverage Score so far: 11.22\n",
      "Episode 9300\tAverage Score so far: 11.22\n",
      "Episode 9400\tAverage Score so far: 11.24\n",
      "Episode 9500\tAverage Score so far: 11.25\n",
      "Episode 9600\tAverage Score so far: 11.25\n",
      "Episode 9700\tAverage Score so far: 11.27\n",
      "Episode 9800\tAverage Score so far: 11.29\n",
      "Episode 9900\tAverage Score so far: 11.30\n",
      "Episode 10000\tAverage Score so far: 11.31\n"
     ]
    }
   ],
   "source": [
    "# Run the training\n",
    "\n",
    "scores = dqn()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# saved the DL weights and architecture that solve the problem\n",
    "import torch\n",
    "torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close environment\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
